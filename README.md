# ğŸš€ MLOps Pipeline with MLflow and DVC

A production-ready MLOps pipeline featuring experiment tracking, model versioning, monitoring, and automated deployment.

## ğŸ¯ Features

- **Experiment Tracking**: MLflow for tracking parameters, metrics, and models
- **Data Versioning**: DVC for dataset and model versioning
- **Model Training**: Automated hyperparameter tuning with scikit-learn
- **Model Serving**: FastAPI REST API with Prometheus metrics
- **Monitoring**: Prediction logging and model drift detection
- **CI/CD Ready**: GitHub Actions workflows included
- **Containerization**: Docker support for easy deployment

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data      â”‚â”€â”€â”€â”€â–¶â”‚   Training   â”‚â”€â”€â”€â”€â–¶â”‚   MLflow    â”‚
â”‚   (DVC)     â”‚     â”‚   Pipeline   â”‚     â”‚  Tracking   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    Model     â”‚
                    â”‚   Registry   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   FastAPI    â”‚â”€â”€â”€â”€â–¶â”‚ Prometheus  â”‚
                    â”‚   Service    â”‚     â”‚ Monitoring  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Installation

### Prerequisites

- Python 3.9+
- Docker (optional)
- AWS/GCP credentials (for DVC remote storage)

### Setup

```bash
# Clone repository
git clone <your-repo-url>
cd mlops-pipeline

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Initialize DVC
dvc init

# Setup MLflow tracking server
mlflow server --host 0.0.0.0 --port 5000
```

## ğŸ”§ Configuration

Edit `config.yaml` to customize:

```yaml
# Model parameters
model:
  name: "RandomForestClassifier"
  param_grid:
    n_estimators: [100, 200, 300]
    max_depth: [10, 20, 30]

# MLflow settings
mlflow:
  tracking_uri: "http://localhost:5000"
  experiment_name: "ml-pipeline-experiment"
```

## ğŸ’» Usage

### 1. Prepare Data

```bash
# Add data to DVC
dvc add data/train.csv
git add data/train.csv.dvc data/.gitignore
git commit -m "Add training data"

# Push to remote storage
dvc push
```

### 2. Train Model

```bash
python train.py
```

This will:
- Load and preprocess data
- Train model with hyperparameter tuning
- Log experiments to MLflow
- Save model artifacts

### 3. Serve Model

```bash
# Start API server
python serve.py

# Or using uvicorn
uvicorn serve:app --host 0.0.0.0 --port 8000 --reload
```

### 4. Make Predictions

```bash
# Single prediction
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "features": [1.0, 2.0, 3.0, 4.0],
    "request_id": "test-001"
  }'

# Batch prediction
curl -X POST "http://localhost:8000/batch-predict" \
  -H "Content-Type: application/json" \
  -d '{
    "data": [[1.0, 2.0, 3.0, 4.0], [5.0, 6.0, 7.0, 8.0]]
  }'
```

## ğŸ“Š MLflow UI

Access MLflow UI at `http://localhost:5000`

Features:
- Compare experiments
- View metrics and parameters
- Download models
- Register models to production

## ğŸ³ Docker Deployment

```bash
# Build image
docker build -t ml-pipeline:latest .

# Run container
docker run -p 8000:8000 ml-pipeline:latest

# Or use docker-compose
docker-compose up
```

## ğŸ“ˆ Monitoring

### Prometheus Metrics

Access metrics at `http://localhost:8000/metrics`

Available metrics:
- Request count
- Request duration
- Prediction distribution
- Model performance

### Prediction Logging

Predictions are logged to `logs/predictions.jsonl` for:
- Model drift detection
- A/B testing
- Performance analysis

## ğŸ§ª Testing

```bash
# Run tests
pytest tests/

# Run with coverage
pytest --cov=. tests/

# Lint code
flake8 .

# Format code
black .
```

## ğŸ“ Project Structure

```
mlops-pipeline/
â”œâ”€â”€ train.py              # Training pipeline
â”œâ”€â”€ serve.py              # FastAPI serving
â”œâ”€â”€ config.yaml           # Configuration
â”œâ”€â”€ requirements.txt      # Dependencies
â”œâ”€â”€ Dockerfile           # Docker configuration
â”œâ”€â”€ docker-compose.yml   # Docker Compose
â”œâ”€â”€ .dvc/                # DVC configuration
â”œâ”€â”€ data/                # Data directory (DVC tracked)
â”‚   â””â”€â”€ train.csv
â”œâ”€â”€ models/              # Model artifacts
â”‚   â”œâ”€â”€ model.pkl
â”‚   â””â”€â”€ scaler.pkl
â”œâ”€â”€ logs/                # Prediction logs
â”œâ”€â”€ tests/               # Unit tests
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/       # CI/CD workflows
â””â”€â”€ README.md
```

## ğŸ”„ CI/CD Pipeline

GitHub Actions workflows included:

1. **Test**: Run tests on PR
2. **Train**: Retrain model on data changes
3. **Deploy**: Deploy to production on merge

## ğŸ“ Best Practices

### Model Training
- Always version your data with DVC
- Log all experiments to MLflow
- Use cross-validation for model selection
- Save preprocessing artifacts

### Model Serving
- Use FastAPI for async performance
- Implement health checks
- Log predictions for monitoring
- Enable caching for frequently requested predictions

### Monitoring
- Track prediction distribution
- Monitor model drift
- Set up alerts for performance degradation
- Review prediction logs regularly

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests
5. Submit a pull request

## ğŸ“„ License

MIT License

## ğŸ™ Acknowledgments

- MLflow for experiment tracking
- DVC for data versioning
- FastAPI for serving
- Prometheus for monitoring

## ğŸ“§ Contact

For questions or suggestions, please open an issue.
